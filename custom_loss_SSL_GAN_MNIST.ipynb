{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_loss_SSL_GAN_MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo7Ulq20A0dt",
        "outputId": "ecee3d86-2841-479b-8c7f-260b8dae328e"
      },
      "source": [
        "from keras.layers import Input, Dense, Reshape, BatchNormalization\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import keras.losses\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        " \n",
        "class GAN():\n",
        "    def __init__(self):\n",
        " \n",
        "        (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
        "        self.batch_size = 100\n",
        "        self.half_batch_size = 50\n",
        "        self.latent_dim = 100\n",
        "        self.iterations = 10000\n",
        "        self.optimizer = Adam(0.0002, 0.5)\n",
        "        self.generator_model = self.generator() \n",
        "        self.discriminator_model, self.classification_model = self.discriminator()\n",
        "        self.combined_model = self.combined()\n",
        "        \n",
        " \n",
        "    def generator(self):\n",
        "        \n",
        "        input_gen = Input(shape = (self.latent_dim,))\n",
        "        hidden1 = BatchNormalization(momentum=0.8)(Dense(256, activation = 'relu')(input_gen))\n",
        "        hidden2 = BatchNormalization(momentum=0.8)(Dense(512, activation = 'relu')(hidden1))\n",
        "        hidden3 = BatchNormalization(momentum=0.8)(Dense(1024, activation = 'relu')(hidden2))\n",
        "        output = Dense(784, activation='tanh')(hidden3)\n",
        "        reshaped_output = Reshape((28, 28, 1))(output)\n",
        "        gen_model = Model(input_gen, reshaped_output)\n",
        "        gen_model.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
        "        print(gen_model.summary())\n",
        "        \n",
        "        \n",
        "        return gen_model\n",
        "    \n",
        "    def discriminator(self):\n",
        "        \n",
        "        input_disc = Input(shape = (784,))\n",
        "        hidden1 = Dense(512, activation = 'relu')(input_disc)\n",
        "        hidden2 = Dense(256, activation = 'relu')(hidden1)\n",
        "        hidden3 = Dense(128, activation = 'relu')(hidden2)\n",
        "        output = Dense(1, activation = 'sigmoid')(hidden3)\n",
        "        output2 = Dense(10, activation = 'softmax', name = 'classification_layer')(hidden3)\n",
        "        disc_model = Model(input_disc, output)\n",
        "        disc_model_2 = Model(input_disc, output2)\n",
        "        disc_model.compile(loss=['binary_crossentropy'], optimizer=self.optimizer, metrics=['accuracy'])\n",
        "        disc_model_2.compile(loss=['categorical_crossentropy'], optimizer=self.optimizer, metrics=['accuracy'])\n",
        "        print(disc_model.summary())\n",
        "        print(disc_model_2.summary())\n",
        "        \n",
        "        return disc_model, disc_model_2\n",
        "    def keras_custom_loss_function (outs,gen_outs):\n",
        "      custom_loss_value=kb.mean(kb.sum(kb.square((outs-gen_outs)/10)))\n",
        "      return custom_loss_value\n",
        "\n",
        "\n",
        "    def combined(self):\n",
        "        \n",
        "        inputs = Input(shape = (self.latent_dim,)) \n",
        "        gen_img = self.generator_model(inputs)\n",
        "        gen_img = Reshape((784,))(gen_img)\n",
        "        self.discriminator_model.trainable = False\n",
        "        outs = self.discriminator_model(gen_img)\n",
        "        comb_model = Model(inputs, outs)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "        comb_model.compile(loss='keras_custom_loss_function', optimizer=optimizer, metrics=['accuracy'])\n",
        "        print(comb_model.summary())\n",
        "        \n",
        "        return comb_model\n",
        "\n",
        "\n",
        "    def sample_1000(self, x, y):\n",
        "        \n",
        "        x_1000 = []\n",
        "        y_1000 = []\n",
        "        for i in range(10):\n",
        "            x_i = x[y==i]\n",
        "            ix = np.random.randint(0, len(x_i), 100)\n",
        "            [x_1000.append(x_i[j]) for j in ix]\n",
        "            [y_1000.append(i) for j in ix]\n",
        "            \n",
        "        return x_1000, y_1000\n",
        "    \n",
        "    def train(self):\n",
        "        \n",
        "        train_data, train_data_y = self.sample_1000(self.x_train, self.y_train)\n",
        "        train_data = ((np.array(train_data).astype(np.float32))-127.5)/127.5\n",
        "        train_data_y = to_categorical(train_data_y)\n",
        "        \n",
        "        all_train_data = ((np.array(self.x_train).astype(np.float32))-127.5)/127.5\n",
        "        all_train_data_y = to_categorical(self.y_train)\n",
        "        \n",
        "        for j in range(self.iterations):\n",
        "            \n",
        "            batch_indx = np.random.randint(0, train_data.shape[0], size = (self.half_batch_size))\n",
        "            batch_x = train_data[batch_indx]\n",
        "            batch_x = batch_x.reshape((-1, 784))\n",
        "            batch_y = train_data_y[batch_indx]\n",
        "            \n",
        "            \n",
        "            batch_indx_total = np.random.randint(0, all_train_data.shape[0], size = (self.half_batch_size))\n",
        "            batch_x_total = all_train_data[batch_indx_total]\n",
        "            batch_x_total = batch_x_total.reshape((-1, 784))\n",
        "            batch_y_total = all_train_data_y[batch_indx_total]\n",
        "            \n",
        "            \n",
        "            input_noise = np.random.normal(0, 1, size=(self.half_batch_size, 100))\n",
        "            gen_outs = self.generator_model.predict(input_noise)\n",
        "            gen_outs = gen_outs.reshape((-1, 784))\n",
        "            \n",
        "            classi_loss = self.classification_model.train_on_batch(batch_x, batch_y)\n",
        "            real_loss1 = self.discriminator_model.train_on_batch(batch_x_total, np.ones((self.half_batch_size,1)))\n",
        "            fake_loss = self.discriminator_model.train_on_batch(gen_outs, np.zeros((self.half_batch_size,1)))     \n",
        "        \n",
        "            \n",
        "            full_batch_input_noise = np.random.normal(0, 1, size=(self.batch_size, 100))\n",
        "            #gan_loss = self.combined_model.train_on_batch(full_batch_input_noise, np.array([1] * self.batch_size))\n",
        "            \n",
        "            if j%1000 == 0:\n",
        "                test_data = ((self.x_test.astype(np.float32)-127.5)/127.5).reshape((-1, 784))\n",
        "                test_results = self.classification_model.predict(test_data)\n",
        "                test_results_argmax = np.argmax(test_results, axis = 1)\n",
        "                \n",
        "                count = 0\n",
        "                for i in range(len(test_results_argmax)):\n",
        "                    if test_results_argmax[i] == self.y_test[i]:\n",
        "                        count += 1\n",
        "                print(\"Accuracy After\", j,\"iterations: \", (count/len(test_data))*100)\n",
        "            \n",
        "            \n",
        "gan = GAN()\n",
        "gan.train()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_14 (Reshape)         (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 566,273\n",
            "Trainable params: 566,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "classification_layer (Dense) (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 567,434\n",
            "Trainable params: 567,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "model_28 (Functional)        (None, 28, 28, 1)         1493520   \n",
            "_________________________________________________________________\n",
            "reshape_15 (Reshape)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "model_29 (Functional)        (None, 1)                 566273    \n",
            "=================================================================\n",
            "Total params: 2,059,793\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 569,857\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4b4cd0e4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4b50254680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Accuracy After 0 iterations:  21.01\n",
            "Accuracy After 1000 iterations:  90.12\n",
            "Accuracy After 2000 iterations:  90.2\n",
            "Accuracy After 3000 iterations:  90.22\n",
            "Accuracy After 4000 iterations:  90.25\n",
            "Accuracy After 5000 iterations:  90.23\n",
            "Accuracy After 6000 iterations:  90.19\n",
            "Accuracy After 7000 iterations:  90.24\n",
            "Accuracy After 8000 iterations:  90.23\n",
            "Accuracy After 9000 iterations:  90.12\n"
          ]
        }
      ]
    }
  ]
}